information
about
nlp
1
the
stanford
corenlp
natural
language
processing
toolkit
this
paper
describe
the
design
and
development
ofstanford
corenlp
a
java
or
at
least
jvm
based
annotation
pipeline
framework
which
provides
most
of
the
common
core
natural
language
processing
nlp
steps
from
tokenization
through
to
coreference
resolution
we
describe
the
original
design
of
the
system
and
its
strengths
section
2
simple
usage
patterns
section
3
the
set
of
provided
annotators
and
how
properties
control
them
section
4
and
how
to
add
additional
annotators
section
5
before
concluding
with
some
higher
level
remarks
and
additional
appendices
while
there
are
several
good
natural
language
analysis
toolkits
stanford
corenlp
is
one
of
the
most
used
and
a
central
theme
is
trying
to
identify
the
attributes
that
contributed
to
its
success
our
pipeline
system
was
initially
designed
for
internal
use
previously
when
combining
multiple
natural
language
analysis
components
each
with
their
own
ad
hoc
apis
we
had
tied
them
together
with
custom
glue
code
the
initial
version
of
the
annotation
pipeline
was
developed
in
2006
in
order
to
replace
this
jumble
with
something
better
a
uniform
interface
was
provided
for
an
annotator
that
adds
some
kind
of
analysis
information
to
some
text
an
annotator
does
this
by
taking
in
an
annotation
object
to
which
it
can
add
extra
information
an
annotation
is
stored
as
a
typesafe
heterogeneous
map
following
the
ideas
for
this
datatype
presented
by
bloch
2008
this
basic
architecture
has
proven
quite
successful
and
is
still
the
basis
of
the
system
described
here
2
natural
language
processing
almost
from
scratch
will
a
computer
program
ever
be
able
to
convert
a
piece
of
english
text
into
a
programmer
friendly
data
structure
that
describes
the
meaning
of
the
natural
language
text
unfortunately
no
consensus
has
emerged
about
the
form
or
the
existence
of
such
a
data
structure
until
such
fundamental
artificial
intelligence
problems
are
resolved
computer
scientists
must
settle
for
the
reduced
objective
of
extracting
simpler
representations
that
describe
limited
aspects
of
the
textual
information
these
simpler
representations
are
often
motivated
by
specific
applications
for
instance
bag
of
words
variants
for
information
retrieval
or
by
our
belief
that
they
capture
something
more
general
about
natural
language
they
can
describe
syntactic
information
e
g
part
of
speech
tagging
chunking
and
parsing
or
semantic
information
e
g
word
sense
disambiguation
semantic
role
labeling
named
entity
extraction
and
anaphora
resolution
text
corpora
have
been
manually
annotated
with
such
data
structures
in
order
to
compare
the
performance
of
various
systems
the
availability
of
standard
benchmarks
has
stimulated
research
in
natural
language
processing
nlp
and
effective
systems
have
been
designed
for
all
these
tasks
such
systems
are
often
viewed
as
software
components
for
constructing
real
world
nlp
solutions
the
overwhelming
majority
of
these
state
of
the
art
systems
address
their
single
benchmark
task
by
applying
linear
statistical
models
to
ad
hoc
features
in
other
words
the
researchers
themselves
discover
intermediate
representations
by
engineering
task
specific
features
these
features
are
often
derived
from
the
output
of
preexisting
systems
leading
to
complex
runtime
dependencies
this
approach
is
effective
because
researchers
leverage
a
large
body
of
linguistic
knowledge
on
the
other
hand
there
is
a
great
temptation
to
optimize
the
performance
of
a
system
for
a
specific
benchmark
although
such
performance
improvements
can
be
very
useful
in
practice
they
teach
us
little
about
the
means
to
progress
toward
the
broader
goals
of
natural
language
understanding
and
the
elusive
goals
of
artificial
intelligence
in
this
contribution
we
try
to
excel
on
multiple
benchmarks
while
avoiding
task
specific
engineering
instead
we
use
a
single
learning
system
able
to
discover
adequate
internal
representations
in
fact
we
view
the
benchmarks
as
indirect
measurements
of
the
relevance
of
the
internal
representations
discovered
by
the
learning
procedure
and
we
posit
that
these
intermediate
representations
are
more
general
than
any
of
the
benchmarks
our
desire
to
avoid
task
specific
engineered
features
prevented
us
from
using
a
large
body
of
linguistic
knowledge
instead
we
reach
good
performance
levels
in
most
of
the
tasks
by
transferring
intermediate
representations
discovered
on
large
unlabeled
data
sets
we
call
this
approach
“almost
from
scratch”
to
emphasize
the
reduced
but
still
important
reliance
on
a
priori
nlp
knowledge
3
natural
language
processing
wikipedia
natural
language
processing
nlp
is
a
subfield
of
linguistics
computer
science
and
artificial
intelligence
concerned
with
the
interactions
between
computers
and
human
language
in
particular
how
to
program
computers
to
process
and
analyze
large
amounts
of
natural
language
data
challenges
in
natural
language
processing
frequently
involve
speech
recognition
natural
language
understanding
and
natural
language
generation
natural
language
processing
has
its
roots
in
the
1950s
already
in
1950
alan
turing
published
an
article
titled
computing
machinery
and
intelligence
which
proposed
what
is
now
called
the
turing
test
as
a
criterion
of
intelligence
a
task
that
involves
the
automated
interpretation
and
generation
of
natural
language
but
at
the
time
not
articulated
as
a
problem
separate
from
artificial
intelligence
4
your
guide
to
natural
language
processing
nlp
in
simple
terms
nlp
represents
the
automatic
handling
of
natural
human
language
like
speech
or
text
and
although
the
concept
itself
is
fascinating
the
real
value
behind
this
technology
comes
from
the
use
cases
nlp
can
help
you
with
lots
of
tasks
and
the
fields
of
application
just
seem
to
increase
on
a
daily
basis
let’s
mention
some
examples
nlp
enables
the
recognition
and
prediction
of
diseases
based
on
electronic
health
records
and
patient’s
own
speech
this
capability
is
being
explored
in
health
conditions
that
go
from
cardiovascular
diseases
to
depression
and
even
schizophrenia
for
example
amazon
comprehend
medical
is
a
service
that
uses
nlp
to
extract
disease
conditions
medications
and
treatment
outcomes
from
patient
notes
clinical
trial
reports
and
other
electronic
health
records
organizations
can
determine
what
customers
are
saying
about
a
service
or
product
by
identifying
and
extracting
information
in
sources
like
social
media
this
sentiment
analysis
can
provide
a
lot
of
information
about
customers
choices
and
their
decision
drivers
an
inventor
at
ibm
developed
a
cognitive
assistant
that
works
like
a
personalized
search
engine
by
learning
all
about
you
and
then
remind
you
of
a
name
a
song
or
anything
you
can’t
remember
the
moment
you
need
it
to
companies
like
yahoo
and
google
filter
and
classify
your
emails
with
nlp
by
analyzing
text
in
emails
that
flow
through
their
servers
and
stopping
spam
before
they
even
enter
your
inbox
to
help
identifying
fake
news
the
nlp
group
at
mit
developed
a
new
system
to
determine
if
a
source
is
accurate
or
politically
biased
detecting
if
a
news
source
can
be
trusted
or
not
amazon’s
alexa
and
apple’s
siri
are
examples
of
intelligent
voice
driven
interfaces
that
use
nlp
to
respond
to
vocal
prompts
and
do
everything
like
find
a
particular
shop
tell
us
the
weather
forecast
suggest
the
best
route
to
the
office
or
turn
on
the
lights
at
home
having
an
insight
into
what
is
happening
and
what
people
are
talking
about
can
be
very
valuable
to
financial
traders
nlp
is
being
used
to
track
news
reports
comments
about
possible
mergers
between
companies
everything
can
be
then
incorporated
into
a
trading
algorithm
to
generate
massive
profits
remember
buy
the
rumor
sell
the
news
nlp
is
also
being
used
in
both
the
search
and
selection
phases
of
talent
recruitment
identifying
the
skills
of
potential
hires
and
also
spotting
prospects
before
they
become
active
on
the
job
market
powered
by
ibm
watson
nlp
technology
legalmation
developed
a
platform
to
automate
routine
litigation
tasks
and
help
legal
teams
save
time
drive
down
costs
and
shift
strategic
focus
nlp
is
particularly
booming
in
the
healthcare
industry
this
technology
is
improving
care
delivery
disease
diagnosis
and
bringing
costs
down
while
healthcare
organizations
are
going
through
a
growing
adoption
of
electronic
health
records
the
fact
that
clinical
documentation
can
be
improved
means
that
patients
can
be
better
understood
and
benefited
through
better
healthcare
the
goal
should
be
to
optimize
their
experience
and
several
organizations
are
already
working
on
this
5
a
simple
introduction
to
natural
language
processing
natural
language
processing
usually
shortened
as
nlp
is
a
branch
of
artificial
intelligence
that
deals
with
the
interaction
between
computers
and
humans
using
the
natural
language
the
ultimate
objective
of
nlp
is
to
read
decipher
understand
and
make
sense
of
the
human
languages
in
a
manner
that
is
valuable
most
nlp
techniques
rely
on
machine
learning
to
derive
meaning
from
human
languages
in
fact
a
typical
interaction
between
humans
and
machines
using
natural
language
processing
could
go
as
follows
1
a
human
talks
to
the
machine
2
the
machine
captures
the
audio
3
audio
to
text
conversion
takes
place
4
processing
of
the
text’s
data
5
data
to
audio
conversion
takes
place
6
the
machine
responds
to
the
human
by
playing
the
audio
file
natural
language
processing
is
the
driving
force
behind
the
following
common
applications
language
translation
applications
such
as
google
translate
word
processors
such
as
microsoft
word
and
grammarly
that
employ
nlp
to
check
grammatical
accuracy
of
texts
interactive
voice
response
ivr
applications
used
in
call
centers
to
respond
to
certain
users’
requests
personal
assistant
applications
such
as
ok
google
siri
cortana
and
alexa
6
natural
language
processing
nlp
what
it
is
and
why
it
matters
natural
language
processing
nlp
is
a
branch
of
artificial
intelligence
that
helps
computers
understand
interpret
and
manipulate
human
language
nlp
draws
from
many
disciplines
including
computer
science
and
computational
linguistics
in
its
pursuit
to
fill
the
gap
between
human
communication
and
computer
understanding
natural
language
processing
helps
computers
communicate
with
humans
in
their
own
language
and
scales
other
language
related
tasks
for
example
nlp
makes
it
possible
for
computers
to
read
text
hear
speech
interpret
it
measure
sentiment
and
determine
which
parts
are
important
today’s
machines
can
analyze
more
language
based
data
than
humans
without
fatigue
and
in
a
consistent
unbiased
way
considering
the
staggering
amount
of
unstructured
data
that’s
generated
every
day
from
medical
records
to
social
media
automation
will
be
critical
to
fully
analyze
text
and
speech
data
efficiently
human
language
is
astoundingly
complex
and
diverse
we
express
ourselves
in
infinite
ways
both
verbally
and
in
writing
not
only
are
there
hundreds
of
languages
and
dialects
but
within
each
language
is
a
unique
set
of
grammar
and
syntax
rules
terms
and
slang
when
we
write
we
often
misspell
or
abbreviate
words
or
omit
punctuation
when
we
speak
we
have
regional
accents
and
we
mumble
stutter
and
borrow
terms
from
other
languages
while
supervised
and
unsupervised
learning
and
specifically
deep
learning
are
now
widely
used
for
modeling
human
language
there’s
also
a
need
for
syntactic
and
semantic
understanding
and
domain
expertise
that
are
not
necessarily
present
in
these
machine
learning
approaches
nlp
is
important
because
it
helps
resolve
ambiguity
in
language
and
adds
useful
numeric
structure
to
the
data
for
many
downstream
applications
such
as
speech
recognition
or
text
analytics
7
ai
natural
language
processing
natural
language
processing
nlp
refers
to
ai
method
of
communicating
with
an
intelligent
systems
using
a
natural
language
such
as
english
processing
of
natural
language
is
required
when
you
want
an
intelligent
system
like
robot
to
perform
as
per
your
instructions
when
you
want
to
hear
decision
from
a
dialogue
based
clinical
expert
system
etc
the
field
of
nlp
involves
making
computers
to
perform
useful
tasks
with
the
natural
languages
humans
use
the
input
and
output
of
an
nlp
system
can
be
−
speech
written
text
there
are
two
components
of
nlp
as
given
−
natural
language
understanding
nlu
understanding
involves
the
following
tasks
−
mapping
the
given
input
in
natural
language
into
useful
representations
analyzing
different
aspects
of
the
language
natural
language
generation
nlg
it
is
the
process
of
producing
meaningful
phrases
and
sentences
in
the
form
of
natural
language
from
some
internal
representation
it
involves
−
text
planning
−
it
includes
retrieving
the
relevant
content
from
knowledge
base
sentence
planning
−
it
includes
choosing
required
words
forming
meaningful
phrases
setting
tone
of
the
sentence
text
realization
−
it
is
mapping
sentence
plan
into
sentence
structure
the
nlu
is
harder
than
nlg
nlp
terminology
phonology
−
it
is
study
of
organizing
sound
systematically
morphology
−
it
is
a
study
of
construction
of
words
from
primitive
meaningful
units
morpheme
−
it
is
primitive
unit
of
meaning
in
a
language
syntax
−
it
refers
to
arranging
words
to
make
a
sentence
it
also
involves
determining
the
structural
role
of
words
in
the
sentence
and
in
phrases
semantics
−
it
is
concerned
with
the
meaning
of
words
and
how
to
combine
words
into
meaningful
phrases
and
sentences
pragmatics
−
it
deals
with
using
and
understanding
sentences
in
different
situations
and
how
the
interpretation
of
the
sentence
is
affected
discourse
−
it
deals
with
how
the
immediately
preceding
sentence
can
affect
the
interpretation
of
the
next
sentence
world
knowledge
−
it
includes
the
general
knowledge
about
the
world
8
what
is
natural
language
processing
natural
language
processing
or
nlp
for
short
is
broadly
defined
as
the
automatic
manipulation
of
natural
language
like
speech
and
text
by
software
the
study
of
natural
language
processing
has
been
around
for
more
than
50
years
and
grew
out
of
the
field
of
linguistics
with
the
rise
of
computers
natural
language
refers
to
the
way
we
humans
communicate
with
each
other
namely
speech
and
text
we
are
surrounded
by
text
think
about
how
much
text
you
see
each
day
signs
menus
email
sms
web
pages
and
so
much
more…
the
list
is
endless
now
think
about
speech
we
may
speak
to
each
other
as
a
species
more
than
we
write
it
may
even
be
easier
to
learn
to
speak
than
to
write
voice
and
text
are
how
we
communicate
with
each
other
given
the
importance
of
this
type
of
data
we
must
have
methods
to
understand
and
reason
about
natural
language
just
like
we
do
for
other
types
of
data
9
natural
language
processing
nlp
natural
language
processing
nlp
is
the
ability
of
a
computer
program
to
understand
human
language
as
it
is
spoken
nlp
is
a
component
of
artificial
intelligence
ai
the
development
of
nlp
applications
is
challenging
because
computers
traditionally
require
humans
to
speak
to
them
in
a
programming
language
that
is
precise
unambiguous
and
highly
structured
or
through
a
limited
number
of
clearly
enunciated
voice
commands
human
speech
however
is
not
always
precise
it
is
often
ambiguous
and
the
linguistic
structure
can
depend
on
many
complex
variables
including
slang
regional
dialects
and
social
context
how
natural
language
processing
works
techniques
and
tools
syntax
and
semantic
analysis
are
two
main
techniques
used
with
natural
language
processing
syntax
is
the
arrangement
of
words
in
a
sentence
to
make
grammatical
sense
nlp
uses
syntax
to
assess
meaning
from
a
language
based
on
grammatical
rules
syntax
techniques
used
include
parsing
grammatical
analysis
for
a
sentence
word
segmentation
which
divides
a
large
piece
of
text
to
units
sentence
breaking
which
places
sentence
boundaries
in
large
texts
morphological
segmentation
which
divides
words
into
groups
and
stemming
which
divides
words
with
inflection
in
them
to
root
forms
semantics
involves
the
use
and
meaning
behind
words
nlp
applies
algorithms
to
understand
the
meaning
and
structure
of
sentences
techniques
that
nlp
uses
with
semantics
include
word
sense
disambiguation
which
derives
meaning
of
a
word
based
on
context
named
entity
recognition
which
determines
words
that
can
be
categorized
into
groups
and
natural
language
generation
which
will
use
a
database
to
determine
semantics
behind
words
10
natural
language
processing
is
fun
computers
are
great
at
working
with
structured
data
like
spreadsheets
and
database
tables
but
us
humans
usually
communicate
in
words
not
in
tables
that’s
unfortunate
for
computers
a
lot
of
information
in
the
world
is
unstructured
—
raw
text
in
english
or
another
human
language
how
can
we
get
a
computer
to
understand
unstructured
text
and
extract
data
from
it
natural
language
processing
or
nlp
is
the
sub
field
of
ai
that
is
focused
on
enabling
computers
to
understand
and
process
human
languages
let’s
check
out
how
nlp
works
and
learn
how
to
write
programs
that
can
extract
information
out
of
raw
text
using
python
as
long
as
computers
have
been
around
programmers
have
been
trying
to
write
programs
that
understand
languages
like
english
the
reason
is
pretty
obvious
—
humans
have
been
writing
things
down
for
thousands
of
years
and
it
would
be
really
helpful
if
a
computer
could
read
and
understand
all
that
data
computers
can’t
yet
truly
understand
english
in
the
way
that
humans
do
—
but
they
can
already
do
a
lot
in
certain
limited
areas
what
you
can
do
with
nlp
already
seems
like
magic
you
might
be
able
to
save
a
lot
of
time
by
applying
nlp
techniques
to
your
own
projects
and
even
better
the
latest
advances
in
nlp
are
easily
accessible
through
open
source
python
libraries
like
spacy
textacy
and
neuralcoref
what
you
can
do
with
just
a
few
lines
of
python
is
amazing
11
natural
language
processing
an
introduction
nlp
began
in
the
1950s
as
the
intersection
of
artificial
intelligence
and
linguistics
nlp
was
originally
distinct
from
text
information
retrieval
ir
which
employs
highly
scalable
statistics
based
techniques
to
index
and
search
large
volumes
of
text
efficiently
manning
et
al1
provide
an
excellent
introduction
to
ir
with
time
however
nlp
and
ir
have
converged
somewhat
currently
nlp
borrows
from
several
very
diverse
fields
requiring
today's
nlp
researchers
and
developers
to
broaden
their
mental
knowledge
base
significantly
early
simplistic
approaches
for
example
word
for
word
russian
to
english
machine
translation
were
defeated
by
homographs—identically
spelled
words
with
multiple
meanings—and
metaphor
leading
to
the
apocryphal
story
of
the
biblical
‘the
spirit
is
willing
but
the
flesh
is
weak’
being
translated
to
‘the
vodka
is
agreeable
but
the
meat
is
spoiled
’
chomsky's
1956
theoretical
analysis
of
language
grammars
provided
an
estimate
of
the
problem's
difficulty
influencing
the
creation
1963
of
backus
naur
form
bnf
notation
bnf
is
used
to
specify
a
‘context
free
grammar'
cfg
and
is
commonly
used
to
represent
programming
language
syntax
a
language's
bnf
specification
is
a
set
of
derivation
rules
that
collectively
validate
program
code
syntactically
‘rules’
here
are
absolute
constraints
not
expert
systems'
heuristics
chomsky
also
identified
still
more
restrictive
‘regular’
grammars
the
basis
of
the
regular
expressions
used
to
specify
text
search
patterns
regular
expression
syntax
defined
by
kleene
1956
was
first
supported
by
ken
thompson's
grep
utility
on
unix
subsequently
1970s
lexical
analyzer
lexer
generators
and
parser
generators
such
as
the
lex
yacc
combination
utilized
grammars
a
lexer
transforms
text
into
tokens
a
parser
validates
a
token
sequence
lexer
parser
generators
simplify
programming
language
implementation
greatly
by
taking
regular
expression
and
bnf
specifications
respectively
as
input
and
generating
code
and
lookup
tables
that
determine
lexing
parsing
decisions
12
natural
language
processing
natural
language
processing
nlp
refers
to
the
branch
of
computer
science—and
more
specifically
the
branch
of
artificial
intelligence
or
ai—concerned
with
giving
computers
the
ability
to
understand
text
and
spoken
words
in
much
the
same
way
human
beings
can
nlp
combines
computational
linguistics—rule
based
modeling
of
human
language—with
statistical
machine
learning
and
deep
learning
models
together
these
technologies
enable
computers
to
process
human
language
in
the
form
of
text
or
voice
data
and
to
‘understand’
its
full
meaning
complete
with
the
speaker
or
writer’s
intent
and
sentiment
nlp
drives
computer
programs
that
translate
text
from
one
language
to
another
respond
to
spoken
commands
and
summarize
large
volumes
of
text
rapidly—even
in
real
time
there’s
a
good
chance
you’ve
interacted
with
nlp
in
the
form
of
voice
operated
gps
systems
digital
assistants
speech
to
text
dictation
software
customer
service
chat
bots
and
other
consumer
conveniences
but
nlp
also
plays
a
growing
role
in
enterprise
solutions
that
help
streamline
business
operations
increase
employee
productivity
and
simplify
mission
critical
business
processes
the
python
programing
language
provides
a
wide
range
of
tools
and
libraries
for
attacking
specific
nlp
tasks
many
of
these
are
found
in
the
natural
language
toolkit
or
nltk
an
open
source
collection
of
libraries
programs
and
education
resources
for
building
nlp
programs
the
nltk
includes
libraries
for
many
of
the
nlp
tasks
listed
above
plus
libraries
for
subtasks
such
as
sentence
parsing
word
segmentation
stemming
and
lemmatization
methods
of
trimming
words
down
to
their
roots
and
tokenization
for
breaking
phrases
sentences
paragraphs
and
passages
into
tokens
that
help
the
computer
better
understand
the
text
it
also
includes
libraries
for
implementing
capabilities
such
as
semantic
reasoning
the
ability
to
reach
logical
conclusions
based
on
facts
extracted
from
text
13
how
to
explain
natural
language
processing
nlp
in
plain
english
that
makes
alexa
and
its
ilk
a
natural
example
of
nlp
in
action
nlp
is
a
core
technology
that
enables
virtual
assistants
to
process
your
verbal
queries
and
respond
with
some
degree
of
accuracy
but
that
doesn’t
necessarily
define
nlp
it
just
points
to
a
popular
real
world
application
of
nlp
plus
the
voice
assistant
example
is
actually
too
narrow
natural
language
processing
isn’t
just
about
speech
but
also
written
text
moreover
nlp
is
already
ubiquitous
and
your
smartphone
assistant
is
only
one
common
example
of
its
everyday
use
“nlp
is
everywhere
and
much
farther
reaching
than
the
more
recently
developed
smart
assistants
”
says
keiland
cooper
director
at
continualai
and
a
neuroscience
researcher
at
the
university
of
california
irvine
“everything
from
search
email
spam
filtering
online
translation
grammar
and
spell
checking
and
many
more
applications
use
nlp
any
machine
learning
that
is
done
involving
natural
language
will
involve
some
form
of
nlp
”
“natural
language
is
just
the
language
humans
use
amongst
themselves
as
opposed
to
programming
languages
which
allow
humans
to
tell
machines
what
to
do
”
says
chris
nicholson
ceo
of
skymind
“english
is
a
natural
language
java
is
a
programming
language
”
programming
languages
are
written
specifically
for
machines
to
understand
our
human
languages
are
not
nlp
enables
clearer
human
to
machine
communication
without
the
need
for
the
human
to
“speak”
java
python
or
any
other
programming
language
“natural
language
processing
is
a
set
of
tools
that
allow
machines
to
extract
information
from
text
or
speech
”
nicholson
explains
14
natural
language
processing
nlp
natural
language
processing
nlp
is
a
field
of
artificial
intelligence
that
enables
computers
to
analyze
and
understand
human
language
it
was
formulated
to
build
software
that
generates
and
comprehends
natural
languages
so
that
a
user
can
have
natural
conversations
with
his
or
her
computer
instead
of
through
programming
or
artificial
languages
like
java
or
c
natural
language
processing
nlp
is
one
step
in
a
larger
mission
for
the
technology
sector
–
namely
to
use
artificial
intelligence
ai
to
simplify
the
way
the
world
works
the
digital
world
has
proved
to
be
a
game
changer
for
a
lot
of
companies
as
an
increasingly
technology
savvy
population
finds
new
ways
of
interacting
online
with
each
other
and
with
companies
social
media
has
redefined
the
meaning
of
community
cryptocurrency
has
changed
the
digital
payment
norm
e
commerce
has
created
a
new
meaning
of
the
word
convenience
and
cloud
storage
has
introduced
another
level
of
data
retention
to
the
masses
through
ai
fields
like
machine
learning
and
deep
learning
are
opening
eyes
to
a
world
of
all
possibilities
machine
learning
is
increasingly
being
used
in
data
analytics
to
make
sense
of
big
data
it
is
also
used
to
program
chat
bots
to
simulate
human
conversations
with
customers
however
these
forward
applications
of
machine
learning
wouldn't
be
possible
without
the
improvisation
of
natural
language
processing
nlp
15
what
is
natural
language
processing
natural
language
processing
nlp
is
the
relationship
between
computers
and
human
language
more
specifically
natural
language
processing
is
the
computer
understanding
analysis
manipulation
and
or
generation
of
natural
language
according
to
dictionary
com
natural
language
refers
to
speech
analysis
in
both
audible
speech
as
well
as
text
of
a
language
nlp
systems
capture
meaning
from
an
input
of
words
sentences
paragraphs
pages
etc
in
the
form
of
a
structured
output
which
varies
greatly
depending
on
the
application
natural
language
processing
is
a
fundamental
element
of
artificial
intelligence
natural
language
processing
however
is
more
than
just
speech
analysis
there
are
a
variety
of
approaches
for
processing
human
language
these
include
symbolic
approach
the
symbolic
approach
to
natural
language
processing
is
based
on
human
developed
rules
and
lexicons
in
other
words
the
basis
behind
this
approach
is
in
generally
accepted
rules
of
speech
within
a
given
language
which
are
materialized
and
recorded
by
linguistic
experts
for
computer
systems
to
follow
statistical
approach
the
statistical
approach
to
natural
language
processing
is
based
on
observable
and
recurring
examples
of
linguistic
phenomena
models
based
on
statistics
recognize
recurring
themes
through
mathematical
analysis
of
large
text
corpora
by
identifying
trends
in
large
samples
of
text
the
computer
system
can
develop
its
own
linguistic
rules
that
it
will
use
to
analyze
future
input
and
or
the
generation
of
language
output
connectionist
approach
the
connectionist
approach
to
natural
language
processing
is
a
combination
of
the
symbolic
and
statistical
approaches
this
approach
starts
with
generally
accepted
rules
of
language
and
tailors
them
to
specific
applications
from
input
derived
from
statistical
inference
16
natural
language
processing
nlp
techniques
for
extracting
information
the
input
to
natural
language
processing
will
be
a
simple
stream
of
unicode
characters
typically
utf
8
basic
processing
will
be
required
to
convert
this
character
stream
into
a
sequence
of
lexical
items
words
phrases
and
syntactic
markers
which
can
then
be
used
to
better
understand
the
content
the
basics
include
structure
extraction
–
identifying
fields
and
blocks
of
content
based
on
tagging
identify
and
mark
sentence
phrase
and
paragraph
boundaries
–
these
markers
are
important
when
doing
entity
extraction
and
nlp
since
they
serve
as
useful
breaks
within
which
analysis
occurs
open
source
possibilities
include
the
lucene
segmenting
tokenizer
and
the
open
nlp
sentence
and
paragraph
boundary
detectors
language
identification
–
will
detect
the
human
language
for
the
entire
document
and
for
each
paragraph
or
sentence
language
detectors
are
critical
to
determine
what
linguistic
algorithms
and
dictionaries
to
apply
to
the
text
open
source
possibilities
include
google
language
detector
or
the
optimize
language
detector
or
the
chromium
compact
language
detector
api
methods
include
bing
language
detection
api
ibm
watson
language
identification
and
google
translation
api
for
language
detection
tokenization
–
to
divide
up
character
streams
into
tokens
which
can
be
used
for
further
processing
and
understanding
tokens
can
be
words
numbers
identifiers
or
punctuation
depending
on
the
use
case
open
source
tokenizers
include
the
lucene
analyzers
and
the
open
nlp
tokenizer
basis
technology
offers
a
fully
featured
language
identification
and
text
analytics
package
called
rosette
base
linguistics
which
is
often
a
good
first
step
to
any
language
processing
software
it
contains
language
identification
tokenization
sentence
detection
lemmatization
decompounding
and
noun
phrase
extraction
search
technologies
has
many
of
these
tools
available
for
english
and
some
other
languages
as
part
of
our
natural
language
processing
toolkit
our
nlp
tools
include
tokenization
acronym
normalization
lemmatization
english
sentence
and
phrase
boundaries
entity
extraction
all
types
but
not
statistical
and
statistical
phrase
extraction
these
tools
can
be
used
in
conjunction
with
the
basis
technology’
solutions
acronym
normalization
and
tagging
–
acronyms
can
be
specified
as
“i
b
m
”
or
“ibm”
so
these
should
be
tagged
and
normalized
search
technologies’
token
processing
has
this
feature
lemmatization
stemming
–
reduces
word
variations
to
simpler
forms
that
may
help
increase
the
coverage
of
nlp
utilities
lemmatization
uses
a
language
dictionary
to
perform
an
accurate
reduction
to
root
words
lemmatization
is
strongly
preferred
to
stemming
if
available
search
technologies
has
lemmatization
for
english
and
our
partner
basis
technologies
has
lemmatization
for
60
languages
stemming
uses
simple
pattern
matching
to
simply
strip
suffixes
of
tokens
e
g
remove
“s”
remove
“ing”
etc
the
open
source
lucene
analyzers
provide
stemming
for
many
languages
decompounding
–
for
some
languages
typically
germanic
scandinavian
and
cyrillic
languages
compound
words
will
need
to
be
split
into
smaller
parts
to
allow
for
accurate
nlp
for
example
“samstagmorgen”
is
“saturday
morning”
in
german
see
wiktionary
german
compound
words
for
more
examples
basis
technology's
solution
has
decompounding
entity
extraction
–
identifying
and
extracting
entities
people
places
companies
etc
is
a
necessary
step
to
simplify
downstream
processing
there
are
several
different
methods
regex
extraction
–
good
for
phone
numbers
id
numbers
e
g
ssn
driver’s
licenses
etc
e
mail
addresses
numbers
urls
hashtags
credit
card
numbers
and
similar
entities
dictionary
extraction
–
uses
a
dictionary
of
token
sequences
and
identifies
when
those
sequences
occur
in
the
text
this
is
good
for
known
entities
such
as
colors
units
sizes
employees
business
groups
drug
names
products
brands
and
so
on
complex
pattern
based
extraction
–
good
for
people
names
made
of
known
components
business
names
made
of
known
components
and
context
based
extraction
scenarios
e
g
extract
an
item
based
on
its
context
which
are
fairly
regular
in
nature
and
when
high
precision
is
preferred
over
high
recall
statistical
extraction
–
use
statistical
analysis
to
do
context
extraction
this
is
good
for
people
names
company
names
geographic
entities
which
are
not
previously
known
and
inside
of
well
structured
text
e
g
academic
or
journalistic
text
statistical
extraction
tends
to
be
used
when
high
recall
is
preferred
over
high
precision
phrase
extraction
–
extracts
sequences
of
tokens
phrases
that
have
a
strong
meaning
which
is
independent
of
the
words
when
treated
separately
these
sequences
should
be
treated
as
a
single
unit
when
doing
nlp
for
example
“big
data”
has
a
strong
meaning
which
is
independent
of
the
words
“big”
and
“data”
when
used
separately
all
companies
have
these
sorts
of
phrases
which
are
in
common
usage
throughout
the
organization
and
are
better
treated
as
a
unit
rather
than
separately
techniques
to
extract
phrases
include
part
of
speech
tagging
–
identifies
phrases
from
noun
or
verb
clauses
statistical
phrase
extraction
identifies
token
sequences
which
occur
more
frequently
than
expected
by
chance
hybrid
uses
both
techniques
together
and
tends
to
be
the
most
accurate
method
17
what
is
natural
language
processing
the
business
benefits
of
nlp
explained
natural
language
processing
nlp
is
the
branch
of
artificial
intelligence
ai
that
deals
with
communication
how
can
a
computer
be
programmed
to
understand
process
and
generate
language
just
like
a
person
while
the
term
originally
referred
to
a
system’s
ability
to
read
it’s
since
become
a
colloquialism
for
all
computational
linguistics
subcategories
include
natural
language
generation
nlg
—
a
computer’s
ability
to
create
communication
of
its
own
—
and
natural
language
understanding
nlu
—
the
ability
to
understand
slang
mispronunciations
misspellings
and
other
variants
in
language
natural
language
processing
works
through
machine
learning
ml
machine
learning
systems
store
words
and
the
ways
they
come
together
just
like
any
other
form
of
data
phrases
sentences
and
sometimes
entire
books
are
fed
into
ml
engines
where
they’re
processed
based
on
grammatical
rules
people’s
real
life
linguistic
habits
or
both
the
computer
then
uses
this
data
to
find
patterns
and
extrapolate
what
comes
next
take
translation
software
for
example
in
french
“i’m
going
to
the
park”
is
“je
vais
au
parc
”
so
machine
learning
predicts
that
“i’m
going
to
the
store”
will
also
begin
with
“je
vais
au
”
all
the
computer
needs
after
that
is
the
word
for
“store
”
machine
translation
is
one
of
the
better
nlp
applications
but
it’s
not
the
most
commonly
used
search
is
every
time
you
look
something
up
in
google
or
bing
you're
feeding
data
into
the
system
when
you
click
on
a
search
result
the
system
sees
this
as
confirmation
that
the
results
it
has
found
are
right
and
uses
this
information
to
better
search
in
the
future
chat
bots
work
the
same
way
they
integrate
with
slack
microsoft
messenger
and
other
chat
programs
where
they
read
the
language
you
use
then
turn
on
when
you
type
in
a
trigger
phrase
voice
assistants
such
as
siri
and
alexa
also
kick
into
gear
when
they
hear
phrases
like
“hey
alexa
”
that’s
why
critics
say
these
programs
are
always
listening
if
they
weren’t
they’d
never
know
when
you
need
them
unless
you
turn
an
app
on
manually
natural
language
processing
programs
must
operate
in
the
background
waiting
for
that
phrase
even
if
they
are
always
there
nlp
isn’t
big
brother
natural
language
processing
does
more
good
for
the
world
than
bad
just
imagine
your
life
without
google
search
or
spellcheck
which
uses
nlp
to
compare
the
words
you
type
to
ones
in
the
dictionary
comparing
the
two
data
sets
allows
spellcheckers
to
identify
what’s
wrong
and
to
offer
suggestions
18
machine
learning
ml
for
natural
language
processing
nlp
machine
learning
ml
for
natural
language
processing
nlp
and
text
analytics
involves
using
machine
learning
algorithms
and
“narrow”
artificial
intelligence
ai
to
understand
the
meaning
of
text
documents
these
documents
can
be
just
about
anything
that
contains
text
social
media
comments
online
reviews
survey
responses
even
financial
medical
legal
and
regulatory
documents
in
essence
the
role
of
machine
learning
and
ai
in
natural
language
processing
and
text
analytics
is
to
improve
accelerate
and
automate
the
underlying
text
analytics
functions
and
nlp
features
that
turn
this
unstructured
text
into
usable
data
and
insights
most
importantly
“machine
learning”
really
means
“machine
teaching
”
we
know
what
the
machine
needs
to
learn
so
our
task
is
to
create
a
learning
framework
and
provide
properly
formatted
relevant
clean
data
for
the
machine
to
learn
from
when
we
talk
about
a
“model
”
we’re
talking
about
a
mathematical
representation
input
is
key
a
machine
learning
model
is
the
sum
of
the
learning
that
has
been
acquired
from
its
training
data
the
model
changes
as
more
learning
is
acquired
unlike
algorithmic
programming
a
machine
learning
model
is
able
to
generalize
and
deal
with
novel
cases
if
a
case
resembles
something
the
model
has
seen
before
the
model
can
use
this
prior
“learning”
to
evaluate
the
case
the
goal
is
to
create
a
system
where
the
model
continuously
improves
at
the
task
you’ve
set
it
19
computational
analysis
and
understanding
of
natural
languages
principles
methods
and
applications
natural
language
processing
nlp
is
an
interdisciplinary
domain
which
is
concerned
with
understanding
natural
languages
as
well
as
using
them
to
enable
human–computer
interaction
natural
languages
are
inherently
complex
and
many
nlp
tasks
are
ill
posed
for
mathematically
precise
algorithmic
solutions
with
the
advent
of
big
data
data
driven
approaches
to
nlp
problems
ushered
in
a
new
paradigm
where
the
complexity
of
the
problem
domain
is
effectively
managed
by
using
large
datasets
to
build
simple
but
high
quality
models
nlp
addresses
issues
in
formal
theories
about
linguistic
knowledge
and
applied
nlp
focuses
on
the
practical
outcome
of
modeling
human
language
with
the
goal
of
creating
software
that
provides
improved
human–machine
interaction
researchers
in
nlp
investigate
but
are
not
limited
to
the
following
topics
•
nl
understanding
involves
conversion
of
human
language
either
input
speech
acoustics
phonology
or
user
typed
written
words
figure
5
18
left
to
right
•
nl
generation
involves
production
of
natural
language
from
an
internal
computer
representation
to
either
written
text
or
spoken
sound
figure
5
18
right
to
left
this
process
often
decomposes
into
three
operations
text
planning
macroplanning
of
text
content
sentence
planning
microplanning
of
sentence
level
organization
and
sentence
realization
grammatical
rendering
in
linear
sentential
form
•
speech
and
acoustic
input
begins
with
the
understanding
of
acoustic
sound
see
figure
5
18
left
box
this
includes
phonology
the
way
sounds
function
within
a
given
language
and
morphology
the
study
of
the
structure
of
word
forms
that
address
issues
of
word
extraction
from
a
spoken
sound
or
dialogue
•
machine
translation
involves
translation
of
text
from
one
language
to
another
•
text
summarization
involves
production
of
summaries
of
texts
that
incorporate
the
essential
information
in
the
text
s
given
the
readers’
interests
nlp
generally
focuses
on
understanding
or
generating
natural
language
at
several
levels
syntax
the
structure
of
words
semantics
the
meaning
of
groups
of
words
pragmatics
the
intent
of
groups
of
words
and
dialogue
the
exchange
of
groups
of
words
between
people
in
generating
language
tutors
generate
phrases
sentences
or
dialogue
they
might
receive
a
command
to
perform
some
communicative
act
pragmatics
or
create
a
structure
that
fixes
the
prepositional
content
of
the
utterance
semantics
that
generates
a
syntactic
structure
or
text
or
sound
the
five
phases
of
nlp
suggested
in
figure
5
18
provide
a
convenient
metaphor
for
the
computational
steps
in
knowledge
based
language
processing
the
semantic
phase
interprets
the
student's
sentences
and
the
pragmatic
phase
interprets
the
student's
intent
however
they
do
not
correspond
directly
to
stages
of
processing
in
fact
many
phases
function
simultaneously
or
iteratively
and
have
dual
aspects
depending
on
whether
the
system
is
understanding
or
generating
natural
language
in
either
case
distinct
internal
data
structure
representations
are
postulated
and
nl
systems
typically
embody
mappings
from
representations
at
one
level
to
representations
at
another
a
tutor
that
manages
mixed
initiative
dialogue
will
both
understand
students’
input
speech
text
and
generate
language
it
might
store
all
speech
input
and
construct
a
data
structure
of
phonemes
20
natural
language
processing
a
cheat
sheet
natural
language
processing
nlp
is
a
cross
discipline
approach
to
making
computers
hear
process
understand
and
duplicate
human
language
fields
including
linguistics
computer
science
and
machine
learning
are
all
a
part
of
the
process
of
nlp
the
results
of
which
can
be
seen
in
things
like
digital
assistants
chat
bots
real
time
translation
apps
and
other
language
using
software
the
concept
of
computers
learning
to
understand
and
use
language
isn't
a
new
one—it
can
arguably
be
traced
all
the
way
back
to
alan
turing's
computing
machinery
and
intelligence
paper
published
in
1950
which
was
where
the
idea
of
the
turing
test
comes
from
in
brief
turing
attempted
to
determine
whether
machines
could
behave
in
a
way
indistinguishable
from
a
human
which
fundamentally
requires
the
ability
to
process
language
and
respond
in
a
sensible
way
since
turing
wrote
his
paper
a
number
of
approaches
to
natural
language
processing
have
emerged
first
came
rules
based
systems
like
eliza
which
were
limited
in
what
they
could
do
to
a
set
of
instructions
systems
like
eliza
were
easy
to
distinguish
from
a
human
because
of
their
formulaic
non
specific
responses
that
quickly
become
repetitive
and
feel
unnatural
it
lacked
understanding
which
is
a
fundamental
part
of
modern
nlp
with
the
advent
of
machine
learning
which
allows
computers
to
algorithmically
develop
their
own
rules
based
on
sample
data
natural
language
processing
exploded
in
ways
turing
never
could
have
predicted
natural
language
processing
has
reached
a
state
where
it's
now
better
at
understanding
human
speech
than
real
humans
even
this
impressive
milestone
still
falls
short
of
truly
complete
nlp
though
because
the
machine
performing
the
work
was
simply
transcribing
language
not
being
asked
to
comprehend
it
modern
nlp
platforms
are
also
capable
of
visually
processing
speech
facebook's
rosetta
for
example
is
able
to
extract
text
in
different
languages
from
more
than
a
billion
images
and
video
frames
in
real
time
techrepublic
sister
site
cnet
said
natural
language
processing
has
a
lot
of
practical
applications
for
a
variety
of
business
uses
google
duplex
is
perhaps
the
most
remarkable
use
of
natural
language
processing
available
as
an
example
today
the
digital
assistant
introduced
in
2018
is
not
only
able
to
understand
complex
statements
but
it
also
speaks
on
the
phone
in
a
way
that's
practically
indistinguishable
from
a
human—vocal
tics
and
all
duplex's
goal
is
to
carry
out
real
world
tasks
over
the
phone
saving
google
users
time
spent
making
appointments
booking
services
placing
orders
and
more
ninety
eight
percent
of
fortune
500
companies
are
now
using
natural
language
processing
software
to
filter
candidates
for
job
searches
with
products
known
as
applicant
tracking
systems
these
products
pick
through
resumes
to
look
for
appropriate
keywords
and
other
linguistic
elements
chat
bots
are
quickly
becoming
the
first
line
of
online
customer
service
with
68
of
consumers
saying
they
had
a
positive
experience
speaking
with
one
these
bots
use
natural
language
processing
to
address
basic
requests
and
problems
while
also
being
able
to
elevate
requests
to
humans
as
needed
uses
of
nlp
in
healthcare
settings
are
numerous
physician
dictation
processing
hand
written
records
compiling
unstructured
healthcare
data
into
usable
formats
and
connecting
natural
language
to
complicated
medical
billing
codes
are
all
potential
uses
nlp
has
also
been
used
recently
to
screen
covid
19
patients
nlp
can
be
used
to
gauge
customer
attitudes
in
call
center
environments
perform
sentiment
analysis
on
social
media
posts
can
be
used
as
part
of
business
intelligence
analysis
and
can
supplement
predictive
analytics
natural
language
processing
has
a
potentially
endless
variety
of
applications
anything
involving
language
can
with
the
right
approach
be
a
use
case
for
nlp
especially
if
it
involves
dealing
with
a
large
volume
of
data
that
would
take
a
human
too
long
to
work
with